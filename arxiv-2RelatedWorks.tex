
% !TeX root=DeepRelAttr.tex
% !TEX TS-program = pdfLatex

%%%%%%%%%%%%%%%%%%%%%%%%%% RELATED WORKS %%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Works}
\label{sec.2}

We usually describe visual concepts with their attributes, and how they look. Attributes are, therefore, mid-level representations for describing objects and scenes. In an early work on attributes, Farhadi \etal~\cite{Farhadi09describingobjects} proposed to describe objects using mid-level attributes. In another work \cite{farhadi10}, they described images based on their attributes, basically a semantic triple <object, action, scene>. Later, Han \etal~\cite{6739133} proposed to describe images at different semantic levels. In the recent years, attributes have shown great performance in object recognition \cite{Farhadi09describingobjects,7298613}, action recognition \cite{6838985,5995353} and event detection \cite{6475038}. Lampert \etal~\cite{6571196} predicted unseen objects using a zero-shot learning framework, in which binary attribute representation of the objects were incorporated. 

On the other hand, comparing attributes enables us to easily and reliably search through high-level data derived from \eg, documents or images. For instance, Kovashka \etal~\cite{KovashkaG13} proposed a relevance feedback strategy for image search using attributes and their comparisons. In order to establish the capacity for comparing attributes, we need to move from binary attributes towards describing attributes relatively. In the recent years, relative attributes have attracted the attention of many researchers, in which a global function is learned for each single attribute. For instance, a linear relative comparison function is learned in \cite{parikh2011}, based on RankSVM \cite{Joachims2002} and a non-linear strategy in \cite{Li2013}. In another work, Datta \etal~\cite{5771429} used trained rankers for each facial image feature and formed a global ranking function for attributes.

Through the process of learning the attributes, different types of low-level image features are incorporated. For instance, Parikh and Grauman~\cite{parikh2011} used 512-dimensional GIST \cite{Aude01} descriptors as image features, while Jayaraman \etal\cite{6909607} used histograms of image features, and reduced their dimensionality using PCA. Other works tried learning attributes through \eg, local and learning \cite{1641014} or fine-grained comparisons \cite{Yu2014}. Yu and Grauman \cite{Yu2014} proposed a local learning-to-rank framework for fine-grained visual comparisons, in which the ranking model is learned using only analogous training comparisons. In another work \cite{Yu2015}, they proposed a local bayesian model to rank images, which are indistinguishable for a given attribute. 

As could be inferred from the literature, it is very hard to decide what low-level image features to use for identifying and comparing visual attributes. Recent studies show that features learned through the convolutional neural networks (CNNs) \cite{NIPS1989_293} (also known as deep features) could achieve great performance for image-based recognition \cite{NIPS2012_4824} and object detection \cite{6909475}. Zhang \etal~\cite{6909608} utilized CNNs for classifying binary attributes. In other works, Escorcia \etal~\cite{Escorcia_2015_CVPR} proposed CCNs with attribute centric nodes within the net for establishing the relationships between visual attributes, Shankar \etal~\cite{Shankar_2015_CVPR} proposed a weakly supervised setting on convolutional neural networks, applied for attribute detection, and Khan \etal~\cite{khan15} used deep features for describing human attributes and thereafter for action recognition. 

CNNs and neural networks have also been extended for learning-to-rank applications. One of the earliest networks for ranking was proposed by Burges\etal~\cite{Burges2005}, known as RankNet. The underlying model in RankNet maps an input feature vector to a Real number. The model is trained  by presenting the network with pairs of input training feature vectors with differing labels. Then based on how they should have been ranked, the underlying model parameters are updated. This model has been used in different fields for ranking and retrieval applications, \eg, for personalized search \cite{song2014} or content-based image retrieval \cite{Wan2014}. 

